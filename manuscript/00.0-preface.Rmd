```{r setup, cache=FALSE, include=FALSE}
devtools::load_all()
is.html = !is.null(output) && output == "html"
only.in.html = "*This chapter is currently only available in this web version. ebook and print will follow.*"

devtools::install_github("viadee/anchorsOnR")
install.packages("../pkg/sbrl_1.2.tar.gz", repos = NULL, type = "source")
```


# Summary {-}
```{r cover, cache=FALSE, eval = is.html, out.width=500, fig.align="center"}
knitr::include_graphics('images/title_page.jpg', dpi = NA)
```

Machine learning has great potential for improving products, processes and research.
But **computers usually do not explain their predictions** which is a barrier to the adoption of machine learning.
This book is about making machine learning models and their decisions interpretable.

After exploring the concepts of interpretability, you will learn about simple, **interpretable models** such as decision trees, decision rules and linear regression.
Later chapters focus on general model-agnostic methods for **interpreting black box models** like feature importance and accumulated local effects and explaining individual predictions with Shapley values and LIME.

All interpretation methods are explained in depth and discussed critically.
How do they work under the hood?
What are their strengths and weaknesses?
How can their outputs be interpreted?
This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.

The book focuses on machine learning models for tabular data (also called relational or structured data) and less on computer vision and natural language processing tasks.
Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.


`r if(is.html){"You can buy the PDF and e-book version (epub, mobi) [on leanpub.com](https://leanpub.com/interpretable-machine-learning)."}`

`r if(is.html){"You can buy the print version [on lulu.com](http://www.lulu.com/shop/christoph-molnar/interpretable-machine-learning/paperback/product-24036234.html)."}`

**About me:** My name is Christoph Molnar, I'm a statistician and a machine learner.
My goal is to make machine learning interpretable.

Mail: christoph.molnar.ai@gmail.com

Website: [https://christophm.github.io/](https://christophm.github.io/)

Follow me on Twitter! [\@ChristophMolnar](https://twitter.com/ChristophMolnar)

Cover by [\@YvonneDoinel](https://twitter.com/YvonneDoinel)


`r if(is.html){"![Creative Commons License](images/by-nc-sa.png)"}`

`r if(is.html){"This book is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."}`



# Preface by the Author {-}

<!-- writing intention -->
When you wanted to learn more about how to interpret machine learning models some years ago, you had a problem.
There was just no place where you can find a good summary.
You had to read the papers or content was scattered all over the place in blogs.
So my initial intent was not to write a book, but to actually learn about the topic of interpretable machine learning.
Interpreting machine learning is a hot and important topic, so it was a bit weird that there was nothing on the topics.
Since I did not find good content about such important topic, I decided to summarize what I learned.
The motivation for this book was not to write a book about how to interpet machine learning models.
My first intention was to learn about it.
So I started reading scientific papers about different methods.
In 2017, I became interested in learning about how to interpret machine learning models.
Started with LIME.
Then more papers.
Certainly, there was already a book or at least some good book about the topic.
Machine learning is already used by many companies, researchers and data scientists.
Did not find anything.
So I started summarizing the methods for interpreting ML models.
So this book was both for me to learn, but also to share with everyone else knowledge about IML.
What started out as a few chapters turned into a full book.


<!-- Introduction to Author -->

<!--
2) introduction to topic and  book structure
-->
So this book is a first in the space of interpretable machine learning.
It is aimed at the practitioner to be about how to apply the methods.
It aims to be one place to look when you want to interpret your model, but are not sure which methods to use.
It's also an introduction to the topic.
Machine learning is here to stay.
And, with some delay -- people realize that interpreting the model is important.
Researchres need it
Developers need it
Companies need it for trust.
This books helps you to understand each method.
Who am I?
Christoph Molnar
PhD student of interpretable machine learning at the LMU.
But not when I started this book.
Background in statistics, so interpetability was always important to me.
Background in applying machine learning in industry, on kaggle and personal projects.

<!-- 3) The third paragraph writing features. It can be explained from the aspects of writing pattern, structure arrangement and practical application. -->
chapters mostly organized by methods.
sometimes more a certain principle of a method, sometimes a concrete implementation.
first about interpretability in general.
then interpretable models.
special focus on model-agnostic methods.
then also some focus on example-based explanations
rounding of with some musings about the future.

Each chapter has a similar structure.
First paragraph summarizes the method.
Then I give some intuition about the method.
The the book goes into the details of the method.
It does not shy away from using math.
I then usually explain some aspects of the method.
Each chapter also has some examples of how the explanations look like.
But this is not an advertisement of the method.
On contrary, it's a critical examination of them.
So each chapter ends with advantages and disadvantages of each method.

This also means you can easily jump between chapters.
And if some chapter depends on other chapter it is explicityl mentioned.

<!-- IMPACT and publishing value-->
Since this book is one of its first book, it has become a valuable asset for many people.
It is a go to place to understand how to interpret machine learning methods.
It is used in universities for introduction of concepts of interpretable machine learning.
It has helped other researchers to learn this, even because they want to do research in interpretability itself, or because they have some model they need to interpret.
And with that model they predict, for example species distribution models.
The book has helped companies to understand models better, debug them and have a better integration into their processes.
So that they derive more value from ML and make less mistakes.


<!-- 5) Messages to the readers, recommended audience -->
Recommended audience:
You should have a basic understanding of ML.
Basic understanding of data analysis.
Not about the code, no code samples.
More about understanding the method deeply.
You should have university level understanding of mathematics to understand the formulas in the book (but it does not mean that you have to hvae visited a university to read the book.)

I hope you enjoy the book.

