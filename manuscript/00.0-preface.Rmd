```{r setup, cache=FALSE, include=FALSE}
devtools::load_all()
is.html = !is.null(output) && output == "html"
only.in.html = "*This chapter is currently only available in this web version. ebook and print will follow.*"

devtools::install_github("viadee/anchorsOnR")
install.packages("../pkg/sbrl_1.2.tar.gz", repos = NULL, type = "source")
```


# Summary {-}
```{r cover, cache=FALSE, eval = is.html, out.width=500, fig.align="center"}
knitr::include_graphics('images/title_page.jpg', dpi = NA)
```

Machine learning has great potential for improving products, processes and research.
But **computers usually do not explain their predictions** which is a barrier to the adoption of machine learning.
This book is about making machine learning models and their decisions interpretable.

After exploring the concepts of interpretability, you will learn about simple, **interpretable models** such as decision trees, decision rules and linear regression.
Later chapters focus on general model-agnostic methods for **interpreting black box models** like feature importance and accumulated local effects and explaining individual predictions with Shapley values and LIME.

All interpretation methods are explained in depth and discussed critically.
How do they work under the hood?
What are their strengths and weaknesses?
How can their outputs be interpreted?
This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.

The book focuses on machine learning models for tabular data (also called relational or structured data) and less on computer vision and natural language processing tasks.
Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.


`r if(is.html){"You can buy the PDF and e-book version (epub, mobi) [on leanpub.com](https://leanpub.com/interpretable-machine-learning)."}`

`r if(is.html){"You can buy the print version [on lulu.com](http://www.lulu.com/shop/christoph-molnar/interpretable-machine-learning/paperback/product-24036234.html)."}`

**About me:** My name is Christoph Molnar, I'm a statistician and a machine learner.
My goal is to make machine learning interpretable.

Mail: christoph.molnar.ai@gmail.com

Website: [https://christophm.github.io/](https://christophm.github.io/)

Follow me on Twitter! [\@ChristophMolnar](https://twitter.com/ChristophMolnar)

Cover by [\@YvonneDoinel](https://twitter.com/YvonneDoinel)


`r if(is.html){"![Creative Commons License](images/by-nc-sa.png)"}`

`r if(is.html){"This book is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."}`



# Preface by the Author {-}

<!-- writing intention -->
Machine learning is a set of powerful techniques that can be used to build products, do research and improve and automate processes.
Machine learning is used to identify fraudulent money transaction, to recommend products to buy, to classify images, to understand species distribution and so on.
Very often it is important that the machine learning models are interpretable.
Interpretability helps the developer to debug and improve the model, to build trust for the model, to justify predictions made by the model and to get insights about the data.
But if you wanted to learn some years ago how to make these machine learning models more interpretable, you had a problem.
The only place you could learn about techniques for making machine learning models interpretable were the research papers or very few blog posts scattered around the internet.
There was no single place that provides a detailed summary about options to break open black box machine learning models.
When I started writing this book, it was not because I necessarily because I wanted to *write* the book, but because I was wishing to *read* the book.
Writing the book about interpretable machine learning was both for learning about the topic and sharing it with others.
I started reading the papers on various techniques for interpretable machine learning (also called explainable artificial intelligence) and summarize them in book chapters.
I shared chapters of the book early on freely on the internet, and many people were interested in the contents, so this kept me going to finish this book which covers many new methods.
My goals was also to be very honest about the techniques, not advertisement, but a critical review.

<!-- Introduction to Author -->
I studied statistics (Bachelor and Master).
Most of my knowledge of machine learning is self-taught through online courses, machine learning competitions, pet projects and jobs.
But of course, knowing statistics is a great foundation.
And also, in statistics the focus is very often to build interpretable regression models.
Interpretable machine learning can benefit a lot from the view of statisticians how to make models interpretable.
When I started writing the first chapters of this book, I was working as a statistician in clinical research, analyzing patient data.
When I do not work on interpretability, I enjoy cooking, cycling and playing video games.

<!--
2) introduction to topic and  book structure
-->
This book (my first book by the way) covers many techniques of interpretable machine learning.
In the first chapters, I introduce the concept of interpretability and motivate why it is needed.
There are even some short stories!
The book will discuss how a good explanation looks like (to humans) and what different properties of an explanation are.
Then we will discuss interpretable models.
These are models that are already build with the goal to be interpretable, for example linear regression models and decision trees.
The main focus of this book are model-agnostic interpretability methods.
Model-agnostic means that these methods can be applied to any machine learning model and are applied after the model has been trained.
This independence of the model makes the model-agnostic methods very flexible and powerful.
Here we discuss many different techniques.
Some techniques explain how individual predictions were made, like local interpretable model-agnostic explanations (lime), Shapley values (and SHAP) and counterfactual explanations.
Other techniques describe the average behavior of the model across a dataset.
Here we will learn about the partial dependence plot, accumulated local effects, permutation feature importance and many more.
A special category are example-based methods, which produce data points as explanations.
Counterfactual explanations, prototypes, influential instances and adversarial examples are example-based methods that are discussed in this book.The book finishes with some musings about how the future could look like for interpretable machine learning.

<!-- 3) The third paragraph writing features. It can be explained from the aspects of writing pattern, structure arrangement and practical application. -->
Most chapters describe one specific interpretation method.
This means that you do not have to read it from front to back, but you can jump between the chapters and focus on techniques that interest you the most.
I only recommend that you start with the introduction and the chapter about interpretability.
The structue of each method chapter is similar.
The first paragraph summarizes the method.
Then I try to build up some intuition about the method, without relying on too much mathematics.
Then, we go deeper and look what is at the core of the method and to get a deep understanding how it works.
Here, you will not be spared, but this will contain some theory and mathematics.
Then the chapter might introduce some specifics of the method.
And most importantly, we will see some examples applied on real data.
The examples give an important understanding how the produced explanations look like.
This book is not an advertisement of the methods, but the goal is that you can think critically about the methods and decide whether a method works well for your needs or not.
So the sections about advantages and disadvantages is a very important part of the book.
Here we try to be very critical and talk about what works well and what are some limitations or problems of the interpretation method.
The last section then talks about available software implementations.

<!-- IMPACT and publishing value-->
Machine learning has received a lot of attention by many people.
Sometimes overhyped by the media, but there was also real uptick in machine learning research and applications.
The need for machine learning interpretability came together with this uptick in applications and research.
For many people this book has become a valuable asset and go-to place when looking for methods to interpret machine learning models.
Teaching instructors use the book to introduce the concepts of interpretable machine learning to their students.
I got e-mails from various Master students, and also PhD students that this book was their starting point and main reference for getting started with machine learning interpretability.
It has helped other researchers how are using machine learning to understand their data.
This reaches across many different domains: ecology, finance, psychology, ...
Data scientists from industry reached out and told me that they use the Intepretable Machine Learning book for their work and recommend it to their colleagues.
Many mistakes can be made when machine learning models are implemented blindly.
So it makes me happy to hear that many people can benefit from this book and become knowledgeable in how to understand their models better.

<!-- 5) Messages to the readers, recommended audience -->
I would recommend this book to practitioners who want an overview of techniques to make their machine learning models more interpretable.
It is also recommended for students and researchers (and anyone else, really) who are interested in the topic.
To benefit from this book, you should already have a basic understanding of machine learning.
You also need understanding of mathematics to follow the theory and formulas in the book, at the level of entry level courses in university.
But you should also be able to understand the intuitive description of the method at the beginning of each chapter without mathematics.

I hope you enjoy the book!

