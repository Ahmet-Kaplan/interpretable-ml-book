```{r setup, cache=FALSE, include=FALSE}
devtools::load_all()
is.html = !is.null(output) && output == "html"
only.in.html = "*This chapter is currently only available in this web version. ebook and print will follow.*"

devtools::install_github("viadee/anchorsOnR")
install.packages("../pkg/sbrl_1.2.tar.gz", repos = NULL, type = "source")
```


# Summary {-}
```{r cover, cache=FALSE, eval = is.html, out.width=500, fig.align="center"}
knitr::include_graphics('images/title_page.jpg', dpi = NA)
```

Machine learning has great potential for improving products, processes and research.
But **computers usually do not explain their predictions** which is a barrier to the adoption of machine learning.
This book is about making machine learning models and their decisions interpretable.

After exploring the concepts of interpretability, you will learn about simple, **interpretable models** such as decision trees, decision rules and linear regression.
Later chapters focus on general model-agnostic methods for **interpreting black box models** like feature importance and accumulated local effects and explaining individual predictions with Shapley values and LIME.

All interpretation methods are explained in depth and discussed critically.
How do they work under the hood?
What are their strengths and weaknesses?
How can their outputs be interpreted?
This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.

The book focuses on machine learning models for tabular data (also called relational or structured data) and less on computer vision and natural language processing tasks.
Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.


`r if(is.html){"You can buy the PDF and e-book version (epub, mobi) [on leanpub.com](https://leanpub.com/interpretable-machine-learning)."}`

`r if(is.html){"You can buy the print version [on lulu.com](http://www.lulu.com/shop/christoph-molnar/interpretable-machine-learning/paperback/product-24036234.html)."}`

**About me:** My name is Christoph Molnar, I'm a statistician and a machine learner.
My goal is to make machine learning interpretable.

Mail: christoph.molnar.ai@gmail.com

Website: [https://christophm.github.io/](https://christophm.github.io/)

Follow me on Twitter! [\@ChristophMolnar](https://twitter.com/ChristophMolnar)

Cover by [\@YvonneDoinel](https://twitter.com/YvonneDoinel)


`r if(is.html){"![Creative Commons License](images/by-nc-sa.png)"}`

`r if(is.html){"This book is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."}`



# Preface by the Author {-}

<!-- writing intention -->
This book started as a side project when I was working as a statistician in clinical research.
I worked 4 days a week, and on my "free" day I worked on side projects.
At some point I got interested in interpretable machine learning and learning about it became a side project.
At first, I had no intention to write a book.
Instead I was simply interested in learning more about interpretable machine learning and searched for good material to learn from.
Given the success of machine learning and the importance of interpretability, I expected there would be books or tutorials to learn about those topics.
The only materials I found were the respective research papers and a few blog posts scattered around the internet, but nothing with a good overview.
No book, no tutorials, no overview papers, nothing.
This gap inspired me to start this book.
I ended up writing the book that I wished was available when I started learning about interpretable machine learning.
My intention with this book was twofold: learning for myself, and also sharing this new knowledge with others.

<!-- Introduction to Author -->
I got my Bachelors and Masters degrees in statistics from the Ludwig Maximilian University of Munich.
Most of my knowledge of machine learning is self-taught through online courses, competitions, side projects and professional jobs.
A background in statistics is a great foundation to get into machine learning, and especially for interpretability.
In statistics, a big focus is building interpretable regression models.
After I finished my Master's degree in statistics, I decided against doing a PhD, because I did not enjoy writing my Master thesis.
Writing just stressed me out too much.
So I took on jobs as data scientist in a fintech startup and as statistician in clinical research.
After these three years in industry, I started writing this book and, some months later, a PhD in interpretable machine learning at the statistical learning and data science chair at the statistics department, Ludwig Maximilian University of Munich.
Writing this book made writing enjoyable again for me and helped me find a passion for research as well.

<!-- Introduction to topic and  book structure -->
This book covers many techniques of interpretable machine learning.
In the first chapters, I introduce the concept of interpretability and motivate why interpretability is needed.
There are even some short stories!
The book will discuss the different properties of explanations and what humans find a good explanation.
Then we will discuss machine learning models that are inherently interpretable, for example regression models and decision trees.
The main focus of this book are model-agnostic interpretability methods.
Model-agnostic means that these methods can be applied to any machine learning model and are applied after the model has been trained.
Independence of the model makes model-agnostic methods very flexible and powerful.
Some techniques explain how individual predictions were made, like local interpretable model-agnostic explanations (LIME) and Shapley values (and SHAP).
Other techniques describe the average behavior of the model across a dataset.
Here we will learn about the partial dependence plot, accumulated local effects, permutation feature importance and many more methods.
A special category are example-based methods, which produce data points as explanations.
Counterfactual explanations, prototypes, influential instances and adversarial examples are example-based methods that are discussed in this book.
The book finishes with some musings about how the future could look like for interpretable machine learning.

<!-- 3) The third paragraph writing features. It can be explained from the aspects of writing pattern, structure arrangement and practical application. -->

You do not have to read the book from front to back, but you can jump between chapters and focus on techniques that interest you the most.
I only recommend that you start with the introduction and the chapter about interpretability.
Most chapters follow a similar structure and focus on one interpretation method.
The first paragraph summarizes the method.
Then I try to build up some intuition about the method, without relying on too much mathematics.
Then, we look at the theory of the method to get a deep understanding how it works.
Here, you will not be spared, as the theory will contain formulas.
I believe one of the best ways to understand a method is through examples.
Therefore, each method will be applied on real data.
Some people say that statistician are very critical about modeling data.
For me, to some degree, this is true, because each chapter contains critical discussions about advantages and disadvantages of each method.
This book is not an advertisement of the methods, but should help you decide whether a method works well for you or not.
The last section of each chapter then talks about available software implementations.

<!-- IMPACT and publishing value-->
Machine learning has received a lot of attention by many people in research and industry.
Sometimes machine learning is overhyped in the media, but there are many real and impactful applications.
Machine learning is a powerful technology to build products, do research and improve and automate processes.
Today, machine learning is used to identify fraudulent money transactions, to recommend movies to watch and to classify images, among many other applications.
Often it is crucial that the machine learning models are intepretable.
Interpretability helps the developer to debug and improve the model, to build trust in the model, to justify model predictions and to get insights about the data.
The increased need for machine learning interpretability is a natural consequence of an increased use of machine learning.
This book has become a valuable resouce for many people to learn about interpret machine learning models.
Teaching instructors use the book to introduce the concepts of interpretable machine learning to their students.
I got e-mails from various Master and PhD students who told me that this book was the starting point and main reference for their theses.
The book has helped applied researchers in ecology, finance, psychology, and so on,  who use machine learning to understand their data.
Data scientists from industry reached out and told me that they use the Intepretable Machine Learning book for their work and recommend it to their colleagues.
When you do not interpret your models or interpret them wrongly, you can run into problems with your machine learning models.
It makes me happy to hear that many people can benefit from this book and become experts in model interpretation.

<!-- 5) Messages to the readers, recommended audience -->
I would recommend this book to practitioners who want an overview of techniques to make their machine learning models more interpretable.
It is also recommended for students and researchers (and anyone else, really) who are interested in the topic.
To benefit from this book, you should already have a basic understanding of machine learning.
You should also have a university entr-level understanding of mathematics to follow the theory and formulas in the book.
But you should also be able to understand the intuitive description of the method at the beginning of each chapter without mathematics.

I hope you enjoy the book!

