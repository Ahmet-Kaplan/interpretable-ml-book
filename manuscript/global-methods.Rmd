```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
```

# Global Model-Agnostic Methods {#global-methods}

Global methods describe the average behavior of a machine learning model.
The counterpart to global methods are [local methods](#local-methods).
We can distinguish between feature effects and importance.
The feature importance quantifies how much a feature contributed to the prediction, which can be measured in different ways.
The feature effect describes how changing a feature changes the prediction.

Global methods are often expressed as expected values, given the distribution of the data.
For example, the [partial dependence plot](#pdp), a feature effect plot, is the expected prediction when all other features are marginalized out.
Describing the average behavior, global model-agnostic methods are especially useful when the modeler wants to understand the general mechanisms of a phenomenon or debug a model.

In this book, you will encounter the following model-agnostic, global interpretation techniques:

* The [partial dependence plot](#pdp) is a feature effect plot.
* [Accumulated local effect plots](#ale), another feature effect method that also works when features are dependent.
* [Feature Interaction](#interaction) with a focus on the H-statistic, which quantifies the interaction between features based on partial dependence plots.
* [Functional Decomposition](#decompostion) is both an idea that is central to interpretability and a technique that decomposes the complex prediction function into smaller parts.
* [Permutation feature importance](#feature-importance) measures the importance as a feature as increase in loss when the feature is permuted.
* [Global Surrogate Models](#global) replace the original model with a simpler model for interpretation.
* [Prototypes and criticisms](#proto) are representative data point of a distribution and can be used to enhance interpretability.

