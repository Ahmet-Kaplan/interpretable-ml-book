```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
```

# Global Model-Agnostic Methods {#global-methods}

Global methods describe the average behavior of a machine learning model.
The counterpart to global methods are [local methods](#local-methods).
Global methods are often expressed as expected values based on the distribution of the data.
For example, the [partial dependence plot](#pdp), a feature effect plot, is the expected prediction when all other features are marginalized out.
Since global interpretation methods describe the average behavior, they are especially useful when the modeler wants to understand the general mechanisms of a phenomenon or debug a model.

In this book, you will encounter the following model-agnostic, global interpretation techniques:

* The [partial dependence plot](#pdp) is a feature effect method.
* [Accumulated local effect plots](#ale) is another feature effect method that also works when features are dependent.
* [Feature interaction (H-statistic)](#interaction) quantifies how much the prediction is a result of joint effects of the features.
* [Functional decomposition](#decompostion) is a central idea of interpretability and a technique that decomposes the complex prediction function into smaller parts.
* [Permutation feature importance](#feature-importance) measures the importance of a feature as increase in loss when the feature is permuted.
* [Global surrogate models](#global) replace the original model with a simpler model for interpretation.
* [Prototypes and criticisms](#proto) are representative data point of a distribution and can be used to enhance interpretability.

