```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
```

<!--{pagebreak}-->

## Functional Decompositon {#decomposition}

Short summary


This chapter introduces both decomposition as mental concept to understand other methods.
But also as its own method.


Problem: ML is high-dimensional function


Idea: Can we decompose it into lower level functions?
Why: Allows disentanglement of effects and importances between features. Also allows visualization for 1 - 3 dims



Example : 1-dim function

Example: 2-dim function

Problem: Not defined what gets into which part, but ignore for now


Formula and how to interpret it and what to do with the individual parts


Estimation:
we need more restrictions to actually estimate individual parts, but that we will see in the functional decomp as method part


## Viewing Other Methods as Decompositions

You might want to come back to this chapter again if you have a good grasp on some of the othre methods.


First on a high level:
Feature effects are direct visualizations of the individual components.
However we have to distinguish between total effect and isolated effect for the higher-order feature effects.
PDP is total effect
ALE is individual effect
If you remove lower effects from PDP, you get fANOVA, at least for indepdentn feature case.

PDP is a direct decomposition, but with additional intercept difference.
ALE is a decomposition.
For permutation feature importance,
Methods such as SHApley and co only describe a prediction with 1-dimensional effects.
What happened with the interaction terms? They are divided among the individual effects.
What happened in PFI with the interactions? They are alos divided among individual effects.

The SHAP interaction plots can also be better understood through decompositions.

## Function Decomposition as Method


References:

- Stein
- Hooker fANOVA 1 and 2
- ALE
- See what Hooker cites
- See newer stuff (HDMR and whatnot)
